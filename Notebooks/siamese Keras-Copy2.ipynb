{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('custom.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./custom/s1.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./custom/s1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3yxf0dR4Hvo"
   },
   "source": [
    "!pip install imutils pandas tensorflow --index-url https://infyartifactory.ad.infosys.com/artifactory/api/pypi/pypi-remote/simple --trusted-host infyartifactory.ad.infosys.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiMQd3PMytXB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os,random\n",
    "from PIL import Image,ImageOps\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from keras.utils.all_utils import Sequence\n",
    "from keras.losses import BinaryCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "# for min pooling\n",
    "from keras import backend as K\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def cv2_imshow(mat):\n",
    "    plt.imshow(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN1_4Jfx4Jyn",
    "outputId": "ea854a6c-81b7-45d5-9e08-02447bfae645"
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./custom/full/001/001_00.png')\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVJFpXI6r4-Q"
   },
   "source": [
    "def make_pairs():\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    # loop over all images\n",
    "    df = pd.read_csv('./custom/train_data.csv').sample(frac=0.01)\n",
    "    path = './custom/full'\n",
    "    for i in tqdm(range(len(df))):\n",
    "        img1 = os.path.join(path, df.iloc[i, 0])\n",
    "        img1 = Image.open(img1)\n",
    "        img1 = img1.resize((725, 359))\n",
    "        img1 = ImageOps.grayscale(img1)\n",
    "        img1 = np.asarray(img1)/255.0\n",
    "        img2 = os.path.join(path, df.iloc[i, 1])\n",
    "        img2 = Image.open(img2)\n",
    "        img2 = img2.resize((725, 359))\n",
    "        img2 = ImageOps.grayscale(img2)\n",
    "        img2 = np.asarray(img2)/255.0\n",
    "        pairImages.append([img1, img2])\n",
    "        pairLabels.append([df.iloc[i, 2]])\n",
    "        \n",
    "    return (np.array(pairImages), np.array(pairLabels))\n",
    "\n",
    "def make_pairs_test():\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    # loop over all images\n",
    "    df = pd.read_csv('./custom/test_data.csv').sample(frac=0.01)\n",
    "    path = './custom/full'\n",
    "    for i in tqdm(range(len(df))):\n",
    "        img1 = os.path.join(path, df.iloc[i, 0])\n",
    "        img1 = Image.open(img1)\n",
    "        img1 = img1.resize((725, 359))\n",
    "        img1 = ImageOps.grayscale(img1)\n",
    "        img1 = np.asarray(img1)/255.0\n",
    "        img2 = os.path.join(path, df.iloc[i, 1])\n",
    "        img2 = Image.open(img2)\n",
    "        img2 = img2.resize((725, 359))\n",
    "        img2 = ImageOps.grayscale(img2)\n",
    "        img2 = np.asarray(img2)/255.0\n",
    "        pairImages.append([img1, img2])\n",
    "        pairLabels.append([df.iloc[i, 2]])\n",
    "        \n",
    "    return (np.array(pairImages), np.array(pairLabels))\n",
    "\n",
    "# build the positive and negative image pairs\n",
    "print(\"[INFO] preparing positive and negative pairs...\")\n",
    "(pairTest, labelTest) = make_pairs_test()\n",
    "\n",
    "# build the positive and negative image pairs\n",
    "print(\"[INFO] preparing positive and negative pairs...\")\n",
    "(pairTrain, labelTrain) = make_pairs()\n",
    "#(pairTrain, labelTrain)[0]\n",
    "#images = []\n",
    "print('Prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmvulqh-z0g6"
   },
   "outputs": [],
   "source": [
    "# specify the shape of the inputs for our network\n",
    "IMG_SHAPE = (359,725,1)\n",
    "# specify the batch size and number of epochs\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, csv_path,\n",
    "                 batch_size,\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path).sample(frac=0.75)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.path = './custom/full'\n",
    "        self.n = len(self.df)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, x):\n",
    "    \n",
    "        img1 = os.path.join(self.path, x)\n",
    "        img1 = Image.open(img1)\n",
    "        img1 = img1.resize((725, 359))\n",
    "        img1 = ImageOps.grayscale(img1)\n",
    "        img1 = np.asarray(img1)/255.0\n",
    "        \n",
    "        return img1\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        X_1 = np.array([self.__get_input(x) for x, y,z in batches.to_numpy()])\n",
    "        X_2 = np.array([self.__get_input(y) for x, y,z in batches.to_numpy()])          \n",
    "        y_batch = np.array([z for x, y,z in batches.to_numpy()])\n",
    "\n",
    "        return X_1,X_2,y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        x1,x2,y = self.__get_data(batches)\n",
    "        return [x1,x2],y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mxivswkMu35"
   },
   "outputs": [],
   "source": [
    "# define the path to the base output directory\n",
    "BASE_OUTPUT = \"./output2\"\n",
    "# use the base output path to derive the path to the serialized\n",
    "# model along with training history plot\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_DAiHI1VChE"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2R02WK7BpBJ"
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y, preds, margin=1):\n",
    "    # explicitly cast the true class label data type to the predicted\n",
    "    # class label data type (otherwise we run the risk of having two\n",
    "    # separate data types, causing TensorFlow to error out)\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "\n",
    "    # calculate the contrastive loss between the true labels and\n",
    "    # the predicted labels\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "\n",
    "    # return the computed contrastive loss to the calling function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtmpwwL5VOaW"
   },
   "outputs": [],
   "source": [
    "def plot_training(H, plotPath):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=60):\n",
    "\t# specify the inputs for the feature extractor network\n",
    "\tinputs = Input(inputShape)\n",
    "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(32, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(32, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # Third set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx =-K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # fourth set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # fifth set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(128, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # sixth set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(128, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # seventh set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(512, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "    # Eighth set of CONV => RELU => POOL => DROPOUT layers\n",
    "\tx = Conv2D(512, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "\tx = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
    "  # prepare the final outputs\n",
    "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
    "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
    "\t# build the model\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\t# return the model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# configure the siamese network\n",
    "print(\"[INFO] building siamese network...\")\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)\n",
    "# finally, construct the siamese network\n",
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
    "\n",
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\",#contrastive_loss\n",
    "    metrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "\n",
    "training_generator = CustomDataGen('./custom/train_data.csv',BATCH_SIZE)\n",
    "validation_generator = CustomDataGen('./custom/val_data.csv',BATCH_SIZE)\n",
    "\n",
    "# Generators\n",
    "history = model.fit(training_generator,\n",
    "                    validation_data=validation_generator,epochs=EPOCHS\n",
    "                    ,batch_size=BATCH_SIZE\n",
    "                    )\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving siamese model...\")\n",
    "model.save(MODEL_PATH)\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting training history...\")\n",
    "plot_training(history,PLOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = os.path.join('./custom/full', path)\n",
    "    img = Image.open(img)\n",
    "    img = img.resize((725, 359))\n",
    "    img = ImageOps.grayscale(img)\n",
    "    img = np.asarray(img)/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./custom/test_data.csv')#.sample(frac=0.05)\n",
    "pred_lis = []\n",
    "true_lis = []\n",
    "for i in range(len(df)):\n",
    "    img1,img2,y = read_image(df.iloc[i,0]),read_image(df.iloc[i,1]),df.iloc[i,2]\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img2 = np.expand_dims(img2, axis=0)\n",
    "    preds = model.predict([img1, img2])\n",
    "    if preds[0][0] <= 0.5:\n",
    "        pred = 0.0\n",
    "    else:\n",
    "        pred = 1.0\n",
    "    pred_lis.append(pred)\n",
    "    true_lis.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(pred_lis, true_lis, labels=[0,1])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_ylabel('Predicted labels');ax.set_xlabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = './custom/full'\n",
    "\n",
    "fold = random.choice(os.listdir(path)).replace('_forg','')\n",
    "\n",
    "org_fold = os.listdir(os.path.join(path,str(fold)))\n",
    "\n",
    "forg_fold = os.listdir(os.path.join(path,str(fold) + '_forg'))\n",
    "\n",
    "org1 = os.path.join(path,str(fold), random.choice(org_fold))\n",
    "org2 = os.path.join(path,str(fold), random.choice(org_fold))\n",
    "\n",
    "forg = os.path.join(path,str(fold) + '_forg', random.choice(forg_fold))\n",
    "\n",
    "\n",
    "imageA = cv2.imread(org1, 0)\n",
    "imageB = cv2.imread(org2, 0)\n",
    "\n",
    "origA = imageA.copy()\n",
    "origB = imageB.copy()\n",
    "\n",
    "# add a batch dimension to both images\n",
    "imageA = np.expand_dims(imageA, axis=0)\n",
    "imageB = np.expand_dims(imageB, axis=0)\n",
    "\n",
    "# scale the pixel values to the range of [0, 1]\n",
    "imageA = imageA / 255.0\n",
    "imageB = imageB / 255.0\n",
    "\n",
    "# use our siamese model to make predictions on the image pair,\n",
    "# indicating whether or not the images belong to the same class\n",
    "preds = model.predict([imageA, imageB])\n",
    "proba = preds[0][0]\n",
    "# initialize the figure\n",
    "fig = plt.figure(\"Pair #{}\".format(1), figsize=(4, 2))\n",
    "plt.suptitle(\"Similarity: {:.2f}\".format(proba))\n",
    "\n",
    "# show first image\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(origA, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# show the second image\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(origB, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "print(org1,org1)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "siameseNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
